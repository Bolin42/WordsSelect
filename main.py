import logging
import os
from image_process import process_images
from check_count import check_file_count
from ocr_alicloud import AliyunOCRBatch
from formatter import batch_process_json_to_txt
import subprocess
import shutil

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

def print_step_header(step_num, step_name, description=""):
    """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ æ­¥éª¤ {step_num}: {step_name}")
    if description:
        print(f"ğŸ“ {description}")
    print(f"{'='*60}")

def print_success(message):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"âœ… {message}")

def print_warning(message):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"âš ï¸  {message}")

def print_error(message):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"âŒ {message}")

def ask_continue(step_name):
    """è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­"""
    while True:
        response = input(f"\næ˜¯å¦ç»§ç»­æ‰§è¡Œ {step_name}ï¼Ÿ(y/n): ").strip().lower()
        if response in ['y', 'yes', 'æ˜¯']:
            return True
        elif response in ['n', 'no', 'å¦']:
            return False
        else:
            print("è¯·è¾“å…¥ y æˆ– n")

def get_sorted_folders(input_dir):
    """è·å–æ­£å¸¸æ’åºçš„æ–‡ä»¶å¤¹åˆ—è¡¨"""
    if not os.path.exists(input_dir):
        print_error(f"è¾“å…¥ç›®å½• {input_dir} ä¸å­˜åœ¨")
        return []
    
    folders = []
    for item in os.listdir(input_dir):
        item_path = os.path.join(input_dir, item)
        if os.path.isdir(item_path):
            folders.append(item)
    
    # æ­£å¸¸é¡ºåºæ’åº
    folders.sort()
    return folders

def merge_txt_to_result(txt_dir='txt', result_dir='result', result_file='final.txt'):
    if not os.path.exists(result_dir):
        os.makedirs(result_dir)
    subdirs = [d for d in os.listdir(txt_dir) if os.path.isdir(os.path.join(txt_dir, d))]
    subdirs.sort()
    for subdir in subdirs:
        sub_txt_dir = os.path.join(txt_dir, subdir)
        sub_result_dir = os.path.join(result_dir, subdir)
        if not os.path.exists(sub_result_dir):
            os.makedirs(sub_result_dir)
        txt_files = [f for f in os.listdir(sub_txt_dir) if f.endswith('.txt')]
        txt_files.sort(key=lambda x: int(os.path.splitext(x)[0]) if os.path.splitext(x)[0].isdigit() else x)
        merged_path = os.path.join(sub_result_dir, 'merged.txt')
        with open(merged_path, 'w', encoding='utf-8') as outfile:
            for fname in txt_files:
                file_path = os.path.join(sub_txt_dir, fname)
                with open(file_path, 'r', encoding='utf-8') as infile:
                    outfile.write(infile.read())
                    outfile.write('\n')
        print_success(f"å·²åˆå¹¶ {len(txt_files)} ä¸ªtxtæ–‡ä»¶åˆ°: {merged_path}")

def check_and_prompt_json_to_txt(json_dir='json', txt_dir='txt', result_dir='result'):
    subdirs = [d for d in os.listdir(json_dir) if os.path.isdir(os.path.join(json_dir, d))]
    subdirs.sort()
    for subdir in subdirs:
        sub_json_dir = os.path.join(json_dir, subdir)
        sub_result_dir = os.path.join(result_dir, subdir)
        has_json = any(f.endswith('.json') for f in os.listdir(sub_json_dir))
        has_result = os.path.exists(sub_result_dir) and any(f.endswith('.txt') for f in os.listdir(sub_result_dir))
        if has_json and not has_result:
            print_warning(f"æ£€æµ‹åˆ° {subdir} æ–‡ä»¶å¤¹ä¸‹æœ‰jsonä½†æ— result/txtï¼Œæ˜¯å¦å…ˆå¤„ç†è¿™äº›json?")
            resp = input(f"æ˜¯å¦å¤„ç† {subdir} çš„jsonæ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
            if resp == 'y':
                from formatter import batch_process_json_to_txt
                batch_process_json_to_txt(json_dir, txt_dir, only_letter=subdir)
                print_success(f"å·²å¤„ç† {subdir} çš„jsonæ–‡ä»¶å¹¶ç”Ÿæˆtxt")

def main():
    print("ğŸ¯ WordsSelect å•è¯æå–ç³»ç»Ÿ")
    print("ğŸ“ å¤„ç†æµç¨‹ï¼šå›¾ç‰‡é¢„å¤„ç† â†’ OCRè¯†åˆ« â†’ å•è¯æå– â†’ ç»“æœåˆå¹¶ â†’ å…ƒæ•°æ®æ¸…ç†")
    print()

    # é…ç½®å‚æ•°
    input_dir = "input"
    processed_dir = "processed"
    json_dir = "json"
    txt_dir = "txt"
    result_dir = "result"
    y1, y2, x1, x2 = 156, 156, 163, 914

    # æ­¥éª¤0: å¯åŠ¨æ—¶ä¼˜å…ˆæ£€æµ‹æœªè½¬txtçš„json
    check_and_prompt_json_to_txt(json_dir, txt_dir, result_dir)

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    folders = get_sorted_folders(input_dir)
    if not folders:
        print_error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¾“å…¥æ–‡ä»¶å¤¹")
        return
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(folders)} ä¸ªè¾“å…¥æ–‡ä»¶å¤¹ï¼ˆæ­£å¸¸é¡ºåºï¼‰:")
    for i, folder in enumerate(folders, 1):
        folder_path = os.path.join(input_dir, folder)
        jpg_count = len([f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')])
        print(f"   {i}. {folder}/ ({jpg_count} ä¸ªjpgæ–‡ä»¶)")
    
    if not ask_continue("å›¾ç‰‡é¢„å¤„ç†"):
        print_warning("ç”¨æˆ·å–æ¶ˆï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # æ­¥éª¤1: å›¾åƒé¢„å¤„ç†
    print_step_header(1, "å›¾åƒé¢„å¤„ç†", "è£å‰ªå’Œæ‹¼æ¥å›¾ç‰‡ï¼ˆæ¯ä¸ªæ–‡ä»¶å¤¹å•ç‹¬è¯¢é—®é¡µé¢ç±»å‹ï¼‰")
    print("ğŸ”„ å¼€å§‹å›¾åƒé¢„å¤„ç†...")
    try:
        process_images(input_dir, processed_dir, y1, y2, x1, x2)
        print_success("å›¾åƒé¢„å¤„ç†å®Œæˆ")
    except Exception as e:
        print_error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        return

    # æ­¥éª¤2: æ–‡ä»¶æ•°é‡æ ¡éªŒ
    print_step_header(2, "æ–‡ä»¶æ•°é‡æ ¡éªŒ", "éªŒè¯å¤„ç†å‰åçš„æ–‡ä»¶æ•°é‡")
    if not check_file_count(input_dir, processed_dir):
        print_error("æ–‡ä»¶æ•°é‡æ ¡éªŒå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
        return
    print_success("æ–‡ä»¶æ•°é‡æ ¡éªŒé€šè¿‡")
    
    if not ask_continue("OCRè¯†åˆ«"):
        print_warning("ç”¨æˆ·å–æ¶ˆï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # æ­¥éª¤3: é˜¿é‡Œäº‘OCRè¯†åˆ«
    print_step_header(3, "é˜¿é‡Œäº‘OCRè¯†åˆ«", "äº‘ç«¯æ–‡å­—è¯†åˆ«ï¼ˆå¯èƒ½äº§ç”Ÿè´¹ç”¨ï¼‰")
    confirm = input("å³å°†è¿›è¡Œé˜¿é‡Œäº‘OCRäº‘ç«¯è¯†åˆ«ï¼Œå¯èƒ½äº§ç”Ÿè´¹ç”¨ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print_warning("å·²å–æ¶ˆäº‘ç«¯å¤„ç†ï¼Œæµç¨‹ç»ˆæ­¢")
        return
    
    print("ğŸ”„ å¼€å§‹é˜¿é‡Œäº‘OCRè¯†åˆ«...")
    try:
        ocr = AliyunOCRBatch()
        ocr.batch_recognize(processed_dir, json_dir)
        print_success("é˜¿é‡Œäº‘OCRè¯†åˆ«å®Œæˆ")
    except Exception as e:
        print_error(f"é˜¿é‡Œäº‘OCRè¯†åˆ«å¤±è´¥: {e}")
        return

    if not ask_continue("JSONè½¬TXT"):
        print_warning("ç”¨æˆ·å–æ¶ˆï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # æ­¥éª¤4: JSONè½¬TXT
    print_step_header(4, "JSONè½¬TXT", "è§£æJSONç”Ÿæˆå•è¯è¡¨")
    print("ğŸ”„ å¼€å§‹è§£æjsonç”Ÿæˆå•è¯è¡¨...")
    try:
        batch_process_json_to_txt(json_dir, txt_dir)
        print_success("JSONè½¬TXTå®Œæˆ")
    except Exception as e:
        print_error(f"JSONè½¬TXTå¤±è´¥: {e}")
        return

    if not ask_continue("åˆå¹¶TXTæ–‡ä»¶"):
        print_warning("ç”¨æˆ·å–æ¶ˆï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # æ­¥éª¤5: åˆå¹¶TXTæ–‡ä»¶
    print_step_header(5, "åˆå¹¶TXTæ–‡ä»¶", "å°†æ‰€æœ‰txtæ–‡ä»¶åˆå¹¶ä¸ºå„è‡ªé¦–å­—æ¯æ€»è¡¨")
    print("ğŸ”„ å¼€å§‹åˆå¹¶æ‰€æœ‰å•è¯è¡¨...")
    try:
        merge_txt_to_result(txt_dir, result_dir, result_file='final.txt')
        print_success("TXTæ–‡ä»¶åˆå¹¶å®Œæˆ")
    except Exception as e:
        print_error(f"TXTæ–‡ä»¶åˆå¹¶å¤±è´¥: {e}")
        return

    if not ask_continue("å…ƒæ•°æ®æ¸…ç†"):
        print_warning("ç”¨æˆ·å–æ¶ˆï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # æ­¥éª¤6: æ¸…ç†å…ƒæ•°æ®
    print_step_header(6, "å…ƒæ•°æ®æ¸…ç†", "æ¸…ç†å¯èƒ½çš„å…ƒæ•°æ®")
    print("ğŸ”„ å¼€å§‹æ¸…ç†å…ƒæ•°æ®...")
    try:
        subprocess.run(['python', 'clean_final_txt.py'], check=True)
        print_success("å…ƒæ•°æ®æ¸…ç†å®Œæˆ")
    except subprocess.CalledProcessError as e:
        print_error(f"å…ƒæ•°æ®æ¸…ç†å¤±è´¥: {e}")
    except FileNotFoundError:
        print_error("æœªæ‰¾åˆ°clean_final_txt.pyè„šæœ¬")

    # å®Œæˆ
    print(f"\n{'='*60}")
    print("ğŸ‰ å…¨éƒ¨æµç¨‹å·²å®Œæˆï¼")
    print("ğŸ“ ç»“æœæ–‡ä»¶ä½ç½®ï¼š")
    print(f"   ğŸ“„ æœ€ç»ˆç»“æœ: {os.path.join(result_dir, 'final.txt')}")
    print(f"   ğŸ“„ æ¸…ç†åç»“æœ: {os.path.join(result_dir, 'cleaned_final.txt')}")
    print(f"{'='*60}")

if __name__ == "__main__":
    main() 