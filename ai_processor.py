#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¤„ç†å™¨ - ä¸“é—¨å¤„ç†AIç›¸å…³åŠŸèƒ½
"""

import os
import time
import requests
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn
from rich.prompt import Prompt, Confirm
import dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# ä».envæ–‡ä»¶è¯»å–APIå¯†é’¥
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")

console = Console()

# å®šä¹‰æ¨¡å‹åˆ—è¡¨ï¼Œå‡ä¸ºç¡…åŸºæµåŠ¨å…è´¹æ¨¡å‹
MODELS = [
    "THUDM/GLM-4-9B-0414",
    "Qwen/Qwen2.5-7B-Instruct",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "Qwen/Qwen2-7B-Instruct",
    "THUDM/GLM-4.1V-9B-Thinking",
    "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    "THUDM/GLM-Z1-9B-0414",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "Qwen/Qwen2.5-7B-Instruct",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "THUDM/GLM-4-9B-0414",
    "Qwen/Qwen3-8B",
    "internlm/internlm2_5-7b-chat",
    "THUDM/glm-4-9b-chat",
    "Qwen/Qwen2-7B-Instruct"
]

def print_step_header(step_num, step_name, description=""):
    """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
    console.print(f"\n{'='*60}")
    console.print(f"ğŸ“‹ æ­¥éª¤ {step_num}: {step_name}")
    if description:
        console.print(f"ğŸ“ {description}")
    console.print(f"{'='*60}")

def print_success(message):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    console.print(f"âœ… {message}")

def print_warning(message):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    console.print(f"âš ï¸  {message}")

def print_error(message):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    console.print(f"âŒ {message}")

def check_model_status(api_key, model):
    """æ£€æŸ¥æ¨¡å‹çŠ¶æ€"""
    try:
        url = "https://api.siliconflow.cn/v1/chat/completions"
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": "Hello"
                }
            ],
            "max_tokens": 10,
            "temperature": 0.1
        }
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        response = requests.post(url, json=payload, headers=headers, timeout=10)
        if response.status_code == 200:
            return True
        else:
            return False
    except Exception:
        return False

def get_available_models(api_key):
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    console.print("ğŸ” æ£€æŸ¥æ¨¡å‹çŠ¶æ€...")
    available_models = []
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        expand=True,
    ) as progress:
        task = progress.add_task("æ£€æŸ¥æ¨¡å‹...", total=len(MODELS))
        
        for model in MODELS:
            progress.update(task, description=f"æ£€æŸ¥ {model}...", advance=1)
            if check_model_status(api_key, model):
                available_models.append(model)
                console.print(f"  âœ… {model} [green]å¯ç”¨[/green]")
            else:
                console.print(f"  âŒ {model} [red]ä¸å¯ç”¨[/red]")
    
    if not available_models:
        print_error("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None
    
    return available_models

def split_file_by_size(file_path, chunk_size=2*1024):
    """æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²æ–‡ä»¶ï¼Œè¿”å›åˆ†å‰²åçš„å†…å®¹åˆ—è¡¨"""
    chunks = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if len(content.encode('utf-8')) <= chunk_size:
            # æ–‡ä»¶å°äºç­‰äºchunk_sizeï¼Œä¸éœ€è¦åˆ†å‰²
            chunks.append(content)
        else:
            # æŒ‰è¡Œåˆ†å‰²æ–‡ä»¶ï¼Œé¿å…å•è¯è¢«æˆªæ–­
            lines = content.splitlines(True)  # ä¿ç•™æ¢è¡Œç¬¦
            current_chunk = ""
            
            for line in lines:
                # æ£€æŸ¥æ·»åŠ è¿™è¡Œåæ˜¯å¦ä¼šè¶…è¿‡chunk_size
                test_chunk = current_chunk + line
                if len(test_chunk.encode('utf-8')) > chunk_size and current_chunk:
                    # å½“å‰å—å·²æ»¡ï¼Œä¿å­˜å¹¶å¼€å§‹æ–°å—
                    chunks.append(current_chunk)
                    current_chunk = line
                else:
                    current_chunk += line
            
            # æ·»åŠ æœ€åä¸€ä¸ªå—
            if current_chunk:
                chunks.append(current_chunk)
                
        return chunks
    except Exception as e:
        print_error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥: {e}")
        return []

def call_qwen_api(content, api_key, model="Qwen/QwQ-32B", available_models=None):
    """è°ƒç”¨ç¡…åŸºæµåŠ¨API"""
    prompt = (
        "è¯·å°†ä»¥ä¸‹å•è¯è¡¨å†…å®¹ä¿®æ­£ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªå•è¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼šã€‚\n"
        "æ¯ä¸€è¡Œéƒ½ç”±ä¸ªå…ƒç´ ç»„æˆï¼Œåˆ†åˆ«ä¸ºï¼š\n"
        "enï¼šè‹±æ–‡å•è¯/è¯ç»„/å¥å­\n"
        "zhï¼šä¸­æ–‡é‡Šä¹‰ï¼Œå¦‚æœä¸­æ–‡é‡Šä¹‰ä¸­é—´å­˜åœ¨åˆ†å·ï¼Œåˆ™åˆ†å·åˆ†å‰²äº†2ä¸ªä¸åŒçš„é‡Šä¹‰ã€‚\n"
        "proï¼šè¯æ€§ï¼ˆæ³¨ï¼šåªæœ‰å•è¯æœ‰è¯æ€§ï¼Œè¯ç»„ä¸å¥å­çš„è¯æ€§è®¾ä¸ºNULLï¼‰\n"
        "typeï¼šenç±»å‹ï¼ˆæ³¨ï¼šå¥å­çš„typeä¸º1,å•è¯çš„typeä¸º0,è¯ç»„çš„typeä¸º-1ï¼‰\n"
        "promtï¼šå¯¹äºtypeä¸ºè¯ç»„å’Œå¥å­çš„en,æ ¹æ®ä¸Šæ–‡ï¼ˆä¸æŸ¥æ‰¾ä¸‹æ–‡ï¼‰æ‰¾å‡ºæœ€æœ‰å¯èƒ½çš„åŸå•è¯ï¼Œå³è¯¥è¯ç»„ä¸­ä¿æœ‰çš„æœ€ä½æœ‰æ•ˆæç¤ºå•è¯\n"
        "å¦‚æœåŸå§‹å†…å®¹æœ‰æ ¼å¼é”™è¯¯ã€ç¼ºå¤±ã€é¡ºåºæ··ä¹±ã€ç¼ºå°‘è¯æ€§ç­‰ï¼Œè¯·è‡ªåŠ¨è¡¥å…¨å’Œä¿®æ­£ã€‚\n"
        "åŒæ—¶ï¼Œå¯¹äºå¤šä¸ªè§£é‡Šï¼Œè¯·å¦èµ·ä¸€è¡Œï¼Œé‡å¤è‹±æ–‡ï¼Œå¹¶ç»§ç»­è¾“å‡ºç›¸å…³å†…å®¹ã€‚å…¶ä¸­â€œ/â€ä¹‹é—´å¯èƒ½æ··æœ‰éŸ³æ ‡ï¼Œè¿™ä¸ªä¸ç®¡ï¼Œç›´æ¥ä¸¢å¼ƒã€‚\n"
        "å•è¯æ€§ã€å•é‡Šä¹‰ç¤ºä¾‹ï¼š\n"
        "|abandon|æ”¾å¼ƒ|vt.|0|NULL|\n"
        "å¤šè¯æ€§ã€å¤šé‡Šä¹‰ç¤ºä¾‹ï¼š\n"
        "è¾“å…¥ä¸ºï¼šcontrary/'kontrari/ n./adj. ç›¸å\n è¾“å‡ºä¸ºï¼š\n"
        "|contrary|ç›¸å|n.|0|NULL|\n"
        "|contrary|ç›¸å|adj.|0|NULL|\n"
        "æˆ–è€…ï¼š\n"
        "è¾“å…¥ä¸ºï¼šshoulder/feulde/ n. è‚©è†€ vt. æŒ‘èµ·ï¼Œæ‰›èµ·ï¼›æ‹…è´Ÿ \n"
        "è¾“å‡ºä¸ºï¼š\n"
        "|shoulder|è‚©è†€|n.|0|NULL|\n"
        "|shoulder|æŒ‘èµ·ï¼Œæ‰›èµ·ï¼›æ‹…è´Ÿ|vt.|0|NULL|\n"
        "å•è¯æ€§ã€å¤šé‡Šä¹‰ç¤ºä¾‹ï¼š\n"
        "è¾“å…¥ä¸ºï¼šconsume /ken'sju:m/ vt.æ¶ˆè´¹ï¼›åƒï¼Œå–ï¼›æ¶ˆè€—\n"
        "è¾“å‡ºä¸ºï¼š\n |consume|æ¶ˆè´¹|vt.|0|NULL|\n |consume|åƒï¼Œå–|vt.|0|NULL|\n |consume|æ¶ˆè€—|vt.|0|NULL|\n"
        "è¯ç»„ç¤ºä¾‹ï¼š\n"
        "|consider doing|è€ƒè™‘åšâ€¦â€¦|NULL|-1|consider|\n"
        "å¥å­ç¤ºä¾‹ï¼š\n"
        "|As we get older, we often find it difficult to understand music.|å¹´é¾„å¢é•¿æ—¶ï¼Œæˆ‘ä»¬å¸¸å¸¸å‘ç°éš¾ä»¥ç†è§£éŸ³ä¹ã€‚|NULL|1|understand|\n"
        "å¦‚æœæœ‰å¤šè¯æ€§æˆ–å¤šä¹‰é¡¹ï¼Œè¯·åˆ†å¤šè¡Œè¾“å‡ºã€‚ä¸è¦è¾“å‡ºå¤šä½™è§£é‡Šå’Œè¯´æ˜ï¼Œåªè¾“å‡ºä¿®æ­£åçš„å†…å®¹ã€‚\n"
        "æ¯ä¸€åˆ—ç”±\"|\"åˆ†å‰²ï¼Œ\"|\"ä¸å†…å®¹ä¹‹é—´ä¸è¦æ·»åŠ ç©ºæ ¼\n"
        "åŸå§‹å†…å®¹å¦‚ä¸‹ï¼š\n"
        f"{content}\n"
        "è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºã€‚"
    )
    
    max_retries = 5
    retry_delay = 10
    
    # æ˜¾ç¤ºå‘é€çš„æ•°æ®åŒ…å¤§å°
    payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªè‹±è¯­å•è¯è¡¨æ ¼å¼ä¿®æ­£åŠ©æ‰‹ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_tokens": 2048,
        "temperature": 0.2
    }
    
    payload_size = len(str(payload).encode('utf-8'))
    console.print(f"  ğŸ“¦ å‘é€æ•°æ®åŒ…å¤§å°: {payload_size} å­—èŠ‚")
    
    # ç¡®å®šè¦å°è¯•çš„æ¨¡å‹åˆ—è¡¨
    if available_models:
        models_to_try = [model] if model in available_models else []
        # æ·»åŠ å…¶ä»–å¯ç”¨æ¨¡å‹ä½œä¸ºå¤‡é€‰
        for m in available_models:
            if m != model and m not in models_to_try:
                models_to_try.append(m)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œåˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨
        models_to_try = [model] + [m for m in MODELS if m != model]
    
    # å¦‚æœé¦–é€‰æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œç»™å‡ºè­¦å‘Š
    if model not in models_to_try:
        print_warning(f"é¦–é€‰æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å…¶ä»–å¯ç”¨æ¨¡å‹")
    
    for model_idx, current_model in enumerate(models_to_try):
        if model_idx > 0:  # å¦‚æœæ˜¯å¤‡ç”¨æ¨¡å‹ï¼Œç»™å‡ºæç¤º
            print_warning(f"åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹: {current_model}")
            
        for attempt in range(max_retries):
            try:
                url = "https://api.siliconflow.cn/v1/chat/completions"
                
                # æ›´æ–°å½“å‰å°è¯•çš„æ¨¡å‹
                payload["model"] = current_model
                
                start_time = time.time()
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }

                response = requests.post(url, json=payload, headers=headers, timeout=60)
                response.raise_for_status()
                
                end_time = time.time()
                response_time = end_time - start_time
                
                # æ˜¾ç¤ºå“åº”ä¿¡æ¯
                response_size = len(response.content)
                speed = response_size / response_time if response_time > 0 else 0
                console.print(f"  ğŸ“¥ å“åº”æ•°æ®åŒ…å¤§å°: {response_size} å­—èŠ‚")
                console.print(f"  ğŸ•’ å“åº”æ—¶é—´: {response_time:.2f} ç§’")
                console.print(f"  ğŸš€ ä¼ è¾“é€Ÿåº¦: {speed:.2f} å­—èŠ‚/ç§’")
                
                result = response.json()
                return result["choices"][0]["message"]["content"], 2*1024  # 2KBå—å¤§å°
                
            except Exception as e:
                error_str = str(e)
                # æ£€æŸ¥æ˜¯å¦æ˜¯502æˆ–503é”™è¯¯
                if "502" in error_str or "503" in error_str:
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        if "502" in error_str:
                            print_warning(f"é‡åˆ°502é”™è¯¯ï¼Œç­‰å¾…{retry_delay}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                        elif "503" in error_str:
                            print_warning(f"é‡åˆ°503é”™è¯¯ï¼Œç­‰å¾…{retry_delay}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        print_error(f"æ¨¡å‹ {current_model} é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
                else:
                    print_error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                    # å¯¹äºé502/503é”™è¯¯ï¼Œä¸å°è¯•å…¶ä»–æ¨¡å‹
                    if model_idx == 0:  # åªæœ‰ä¸»æ¨¡å‹æ‰å°è¯•å¤‡ç”¨æ¨¡å‹
                        break
                    return None, 2*1024
    
    return None, 2*1024

def parse_fixed_content(content):
    """è§£æä¿®æ­£åçš„å†…å®¹"""
    records = []
    lines = content.strip().split('\n')
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        if not line or not line.startswith('|'):
            continue
            
        try:
            # ç§»é™¤é¦–å°¾çš„|ç¬¦å·å¹¶åˆ†å‰²
            parts = line.strip('|').split('|')
            if len(parts) >= 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å­—æ®µ
                # å®‰å…¨åœ°è½¬æ¢typeå­—æ®µ
                try:
                    type_value = int(parts[3])
                except ValueError:
                    print_warning(f"ç¬¬{line_num}è¡Œtypeå­—æ®µè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0: {parts[3]}")
                    type_value = 0
                
                record = {
                    'en': parts[0],
                    'zh': parts[1],
                    'pro': parts[2] if parts[2] != 'NULL' else None,
                    'type': type_value,
                    'promt': parts[4] if parts[4] != 'NULL' else None
                }
                records.append(record)
            else:
                print_warning(f"ç¬¬{line_num}è¡Œå­—æ®µä¸è¶³ï¼Œè·³è¿‡: {line}")
        except Exception as e:
            print_warning(f"ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {line}, é”™è¯¯: {e}")
    
    return records

def process_single_letter(subdir, txt_file, ai_output_dir, api_key, model, available_models):
    """å¤„ç†å•ä¸ªå­—æ¯ç›®å½•"""
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        ai_subdir = os.path.join(ai_output_dir, subdir)
        os.makedirs(ai_subdir, exist_ok=True)
        
        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
        console.print(f"\n:brain: å¤„ç†: {subdir}")
        console.print(f"  ğŸ“„ æºæ–‡ä»¶: {txt_file}")
        console.print(f"  ğŸ“ è¾“å‡ºç›®å½•: {ai_subdir}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        if os.path.getsize(txt_file) == 0:
            print_warning(f"æ–‡ä»¶ {txt_file} ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
            return True
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(txt_file)
        console.print(f"  ğŸ“„ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        # å…ˆå°è¯•è°ƒç”¨APIè·å–åˆé€‚çš„å—å¤§å°
        with open(txt_file, 'r', encoding='utf-8') as f:
            test_content = f.read(1000)  # è¯»å–å‰1000ä¸ªå­—ç¬¦ä½œä¸ºæµ‹è¯•
        
        # è·å–æ¨¡å‹å’Œå—å¤§å°
        fixed_content, chunk_size = call_qwen_api(test_content, api_key, model, available_models)
        if fixed_content is None:
            print_error(f"æ— æ³•è·å–æ¨¡å‹ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å—å¤§å°")
            chunk_size = 2*1024  # é»˜è®¤2KB
        
        console.print(f"  ğŸ§  ä½¿ç”¨æ¨¡å‹æ¨èå—å¤§å°: {chunk_size} å­—èŠ‚")
        
        # åˆ†å‰²æ–‡ä»¶ä¸ºæŒ‡å®šå¤§å°çš„å—
        chunks = split_file_by_size(txt_file, chunk_size)
        console.print(f"  ğŸ”ª åˆ†å‰²ä¸º {len(chunks)} å—")
        
        if not chunks:
            print_warning(f"æ–‡ä»¶ {txt_file} æ— æ³•åˆ†å‰²")
            return True
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²å¤„ç†çš„å—æ–‡ä»¶ï¼Œå®ç°æ–­ç‚¹æ¢å¤
        processed_chunks = set()
        if os.path.exists(ai_subdir):
            for file_name in os.listdir(ai_subdir):
                if file_name.startswith("chunk_") and file_name.endswith(".txt"):
                    try:
                        chunk_num = int(file_name.split("_")[1].split(".")[0])
                        processed_chunks.add(chunk_num - 1)  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                    except:
                        pass
        
        # æ”¶é›†æ‰€æœ‰è®°å½•
        all_records = []
        
        # å¦‚æœæœ‰å·²å¤„ç†çš„å—ï¼ŒåŠ è½½å®ƒä»¬çš„è®°å½•
        for chunk_idx in processed_chunks:
            if chunk_idx < len(chunks):
                chunk_output_path = os.path.join(ai_subdir, f"chunk_{chunk_idx + 1}.txt")
                if os.path.exists(chunk_output_path):
                    try:
                        with open(chunk_output_path, 'r', encoding='utf-8') as f:
                            fixed_content = f.read()
                        records = parse_fixed_content(fixed_content)
                        all_records.extend(records)
                        console.print(f"  ğŸ”„ æ¢å¤å·²å¤„ç†å— {chunk_idx + 1}")
                    except Exception as e:
                        print_warning(f"æ¢å¤å— {chunk_idx + 1} å¤±è´¥: {e}")
        
        # å¤„ç†æœªå®Œæˆçš„å—
        start_time = time.time()
        completed_chunks = len(processed_chunks)
        total_chunks = len(chunks)
        
        for i, chunk in enumerate(chunks):
            # å¦‚æœå—å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡
            if i in processed_chunks:
                continue
                
            try:
                # è®¡ç®—å‰©ä½™æ—¶é—´
                if completed_chunks > 0:
                    elapsed_time = time.time() - start_time
                    avg_time_per_chunk = elapsed_time / completed_chunks
                    remaining_chunks = total_chunks - completed_chunks
                    estimated_remaining_time = avg_time_per_chunk * remaining_chunks
                else:
                    estimated_remaining_time = 0
                    
                # æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡ä¿¡æ¯
                stats_text = f"[cyan]å·²å¤„ç†: {completed_chunks}/{total_chunks} å—, "
                stats_text += f"å‰©ä½™: {total_chunks - completed_chunks} å—, "
                stats_text += f"é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining_time:.1f} ç§’[/cyan]"
                console.print(stats_text)
                
                # æ˜¾ç¤ºå½“å‰å—å¤§å°
                chunk_size_bytes = len(chunk.encode('utf-8'))
                console.print(f"  ğŸ“¦ å— {i+1} å¤§å°: {chunk_size_bytes} å­—èŠ‚")
                
                # è°ƒç”¨AI APIå¤„ç†
                fixed_content, _ = call_qwen_api(chunk, api_key, model, available_models)
                if fixed_content is None:
                    print_error(f"AIå¤„ç†å— {i+1} å¤±è´¥")
                    return False
                
                # æ˜¾ç¤ºAIè¿”å›å†…å®¹çš„å‰200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                preview_content = fixed_content[:200] + ("..." if len(fixed_content) > 200 else "")
                console.print(f"  ğŸ§¾ AIè¿”å›å†…å®¹é¢„è§ˆ: {preview_content}")
                
                # ä¿å­˜AIè¾“å‡ºåˆ°æ–‡ä»¶
                chunk_output_path = os.path.join(ai_subdir, f"chunk_{i+1}.txt")
                with open(chunk_output_path, 'w', encoding='utf-8') as f:
                    f.write(fixed_content)
                
                # æ˜¾ç¤ºAIè¾“å‡ºå¤§å°
                output_size = len(fixed_content.encode('utf-8'))
                console.print(f"  ğŸ’¾ ä¿å­˜å— {i+1} è¾“å‡ºåˆ°: {chunk_output_path} ({output_size} å­—èŠ‚)")
                
                # è§£æå¤„ç†ç»“æœ
                records = parse_fixed_content(fixed_content)
                all_records.extend(records)
                
                completed_chunks += 1
                
                # é˜²æ­¢APIé™æµ
                time.sleep(0.5)
                
            except Exception as e:
                print_error(f"å¤„ç†å— {i+1} å¤±è´¥: {e}")
                # æ‰“å°å®Œæ•´çš„tracebackä»¥ä¾¿è°ƒè¯•
                import traceback
                traceback.print_exc()
                return False
        
        # ä¿å­˜åˆå¹¶åçš„ç»“æœ
        merged_output_path = os.path.join(ai_subdir, f'{subdir}.txt')
        with open(merged_output_path, 'w', encoding='utf-8') as f:
            for record in all_records:
                f.write(f"|{record['en']}|{record['zh']}|{record['pro'] or 'NULL'}|{record['type']}|{record['promt'] or 'NULL'}|\n")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦æ­£ç¡®ç”Ÿæˆ
        if os.path.exists(merged_output_path):
            merged_size = os.path.getsize(merged_output_path)
            print_success(f"å®Œæˆå¤„ç†: {subdir} ({len(all_records)} æ¡è®°å½•)ï¼Œç»“æœä¿å­˜è‡³: {merged_output_path} ({merged_size} å­—èŠ‚)")
        else:
            print_error(f"å®Œæˆå¤„ç†: {subdir} ({len(all_records)} æ¡è®°å½•)ï¼Œä½†åˆå¹¶æ–‡ä»¶æœªæ­£ç¡®ç”Ÿæˆ: {merged_output_path}")
        
        return True
        
    except Exception as e:
        print_error(f"å¤„ç† {subdir} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def batch_process_ai(result_dir='result', ai_output_dir='ai', api_key=None, model="Qwen/QwQ-32B", available_models=None, selected_letters=None):
    """æ‰¹é‡å¤„ç†resultç›®å½•ä¸‹çš„æ–‡ä»¶ï¼ŒAIå¤„ç†ç»“æœä¿å­˜åˆ°aiç›®å½•"""
    if not api_key:
        print_error("æœªæä¾›APIå¯†é’¥")
        return False
    
    # æ£€æŸ¥resultç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(result_dir):
        print_error(f"ç›®å½• {result_dir} ä¸å­˜åœ¨")
        return False
    
    print_step_header(1, "AIå¤„ç†", f"å¤„ç†ç›®å½•: {result_dir}")
    
    # è·å–æ‰€æœ‰å­—æ¯ç›®å½•
    subdirs = [d for d in os.listdir(result_dir) if os.path.isdir(os.path.join(result_dir, d))]
    subdirs.sort()
    
    if not subdirs:
        print_warning("æœªæ‰¾åˆ°ä»»ä½•å­—æ¯ç›®å½•")
        return False
    
    # è¿‡æ»¤æ‰ç©ºçš„å­æ–‡ä»¶å¤¹
    valid_subdirs = []
    for subdir in subdirs:
        subdir_path = os.path.join(result_dir, subdir)
        txt_file = os.path.join(subdir_path, f'{subdir}.txt')
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”txtæ–‡ä»¶å­˜åœ¨ä¸”éç©º
        if os.path.exists(txt_file) and os.path.getsize(txt_file) > 0:
            valid_subdirs.append(subdir)
        elif os.path.exists(txt_file):
            print_warning(f"è·³è¿‡ {subdir}ï¼Œæ–‡ä»¶ä¸ºç©º: {txt_file}")
        else:
            print_warning(f"è·³è¿‡ {subdir}ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
    
    if not valid_subdirs:
        print_warning("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å­—æ¯ç›®å½•")
        return False
    
    # å¦‚æœæŒ‡å®šäº†è¦å¤„ç†çš„å­—æ¯ï¼Œåˆ™è¿‡æ»¤
    if selected_letters:
        filtered_subdirs = []
        for subdir in valid_subdirs:
            if subdir in selected_letters:
                filtered_subdirs.append(subdir)
        valid_subdirs = filtered_subdirs
    
    # æ˜¾ç¤ºå¤„ç†æ¦‚è§ˆ
    from rich.table import Table
    table = Table(title="å¤„ç†æ¦‚è§ˆ")
    table.add_column("ID", style="blue", justify="right")
    table.add_column("å­—æ¯", style="cyan")
    table.add_column("çŠ¶æ€", style="magenta")
    table.add_column("æ–‡ä»¶å¤§å°", style="green")
    
    total_size = 0
    for idx, subdir in enumerate(valid_subdirs, 1):
        subdir_path = os.path.join(result_dir, subdir)
        txt_file = os.path.join(subdir_path, f'{subdir}.txt')
        size = os.path.getsize(txt_file)
        total_size += size
        table.add_row(str(idx), subdir, "å¾…å¤„ç†", f"{size} bytes")
    
    console.print(table)
    console.print(f"[bold]æ€»è®¡: {len(valid_subdirs)} ä¸ªå­—æ¯, {total_size} å­—èŠ‚[/bold]")
    console.print(f"[bold]ä½¿ç”¨æ¨¡å‹: {model}[/bold]")
    
    # å¤„ç†æ¯ä¸ªå­—æ¯ç›®å½•
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        expand=True,
        refresh_per_second=10
    ) as progress:
        # ä¸»è¿›åº¦æ¡ - å­—æ¯å¤„ç†è¿›åº¦
        main_task = progress.add_task("æ€»è¿›åº¦", total=len(valid_subdirs))
        
        for subdir_idx, subdir in enumerate(valid_subdirs):
            subdir_path = os.path.join(result_dir, subdir)
            txt_file = os.path.join(subdir_path, f'{subdir}.txt')
            
            # æ›´æ–°ä¸»è¿›åº¦æ¡æè¿°
            progress.update(main_task, description=f"å¤„ç† {subdir} ({subdir_idx+1}/{len(valid_subdirs)})")
            
            # æ ‡è®°é¦–å­—æ¯æ˜¯å¦å¤„ç†æˆåŠŸ
            letter_processed_successfully = False
            max_letter_attempts = 3
            
            for letter_attempt in range(max_letter_attempts):
                # å¤„ç†å•ä¸ªå­—æ¯
                result = process_single_letter(subdir, txt_file, ai_output_dir, api_key, model, available_models)
                
                if result:  # æˆåŠŸå¤„ç†
                    letter_processed_successfully = True
                    break
                else:
                    # å¤„ç†å¤±è´¥ï¼Œéœ€è¦é‡æ–°å°è¯•
                    if letter_attempt < max_letter_attempts - 1:
                        print_warning(f"é¦–å­—æ¯ {subdir} å¤„ç†å¤±è´¥ï¼Œç­‰å¾…15ç§’åé‡æ–°å°è¯• (ç¬¬ {letter_attempt + 2}/{max_letter_attempts} æ¬¡)...")
                        time.sleep(15)
                        continue
                    else:
                        print_error(f"é¦–å­—æ¯ {subdir} å¤„ç†å¤±è´¥ï¼Œå·²å°è¯• {max_letter_attempts} æ¬¡ï¼Œè·³è¿‡å¤„ç†")
            
            # æ›´æ–°ä¸»è¿›åº¦æ¡
            progress.advance(main_task)
            
            # ç¡®ä¿æœ‰é€‚å½“çš„å»¶è¿Ÿï¼Œé¿å…APIé™æµ
            time.sleep(2)
    
    print_success(f"AIå¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {ai_output_dir}")
    return True

def parse_letter_selection(selection_str, available_letters):
    """è§£æå­—æ¯é€‰æ‹©å­—ç¬¦ä¸²ï¼Œæ”¯æŒå•ä¸ªå­—æ¯ã€èŒƒå›´å’Œåˆ—è¡¨"""
    if not selection_str or selection_str.lower() == "all":
        return available_letters
    
    selected = set()
    parts = selection_str.split(',')
    
    for part in parts:
        part = part.strip().lower()
        if '-' in part and len(part) == 3:  # èŒƒå›´ï¼Œå¦‚ a-c
            start, end = part.split('-')
            if start.isalpha() and end.isalpha():
                start_ord = ord(start)
                end_ord = ord(end)
                for i in range(min(start_ord, end_ord), max(start_ord, end_ord) + 1):
                    letter = chr(i)
                    if letter in available_letters:
                        selected.add(letter)
        elif part.isalpha() and len(part) == 1:  # å•ä¸ªå­—æ¯
            if part in available_letters:
                selected.add(part)
    
    return sorted(list(selected))

def main():
    console.rule("[bold green]AIå¤„ç†å™¨")
    console.print("[bold yellow]æ¬¢è¿ä½¿ç”¨AIå¤„ç†å™¨ï¼[/bold yellow] :brain:")
    
    # è·å–APIå¯†é’¥ - ä¼˜å…ˆä».envæ–‡ä»¶è¯»å–
    api_key = SILICONFLOW_API_KEY
    if not api_key:
        api_key = Prompt.ask("è¯·è¾“å…¥SiliconFlow APIå¯†é’¥")
        if not api_key:
            print_error("æœªæä¾›APIå¯†é’¥")
            return
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    available_models = get_available_models(api_key)
    if not available_models:
        print_error("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    console.print("\n[bold green]å¯ç”¨æ¨¡å‹åˆ—è¡¨:[/bold green]")
    for i, model in enumerate(available_models, 1):
        console.print(f"  {i}. {model}")
    
    # è·å–è¾“å…¥ç›®å½•
    result_dir = Prompt.ask("è¯·è¾“å…¥resultç›®å½•è·¯å¾„", default="result")
    
    # è·å–AIè¾“å‡ºç›®å½•
    ai_output_dir = Prompt.ask("è¯·è¾“å…¥AIè¾“å‡ºç›®å½•è·¯å¾„", default="ai")
    
    # è·å–æ¨¡å‹åç§°ï¼ˆé»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹ï¼‰
    default_model = available_models[0]
    model = Prompt.ask("è¯·è¾“å…¥æ¨¡å‹åç§°", default=default_model)
    
    # è·å–æ‰€æœ‰å¯ç”¨å­—æ¯
    if os.path.exists(result_dir):
        subdirs = [d for d in os.listdir(result_dir) if os.path.isdir(os.path.join(result_dir, d))]
        subdirs.sort()
        valid_subdirs = []
        for subdir in subdirs:
            subdir_path = os.path.join(result_dir, subdir)
            txt_file = os.path.join(subdir_path, f'{subdir}.txt')
            if os.path.exists(txt_file) and os.path.getsize(txt_file) > 0:
                valid_subdirs.append(subdir)
    else:
        valid_subdirs = []
    
    # æ˜¾ç¤ºå¯ç”¨å­—æ¯å¹¶è·å–ç”¨æˆ·é€‰æ‹©
    if valid_subdirs:
        console.print("\n[bold green]å¯ç”¨å­—æ¯:[/bold green]")
        letters_display = ", ".join(valid_subdirs)
        console.print(f"  {letters_display}")
        selection_help = "è¾“å…¥è¦å¤„ç†çš„å­—æ¯ï¼ˆå¦‚: a, b, c æˆ– a-c æˆ– allï¼‰"
        selected_str = Prompt.ask(selection_help, default="all")
        selected_letters = parse_letter_selection(selected_str, valid_subdirs)
    else:
        selected_letters = None
    
    # ç¡®è®¤æ‰§è¡Œ
    if not Confirm.ask("æ˜¯å¦å¼€å§‹AIå¤„ç†?"):
        console.print("[yellow]å·²å–æ¶ˆæ“ä½œ[/yellow]")
        return
    
    # æ‰§è¡ŒAIå¤„ç†
    batch_process_ai(result_dir, ai_output_dir, api_key, model, available_models, selected_letters)

if __name__ == "__main__":
    main()